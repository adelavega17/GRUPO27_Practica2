{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Drive Gaston"
      ],
      "metadata": {
        "id": "-4bg3zVeCtv5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uQAnEBgBu6T",
        "outputId": "9c4c8938-354c-412f-c6ea-9c6775334fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "drive  sample_data\n",
            "/content/drive/MyDrive/Aprendizaje\n",
            "attrition_available_27.pkl  final_tree.joblib\t     tennis.txt\n",
            "comp_st27ns1.txt.bz2\t    high_correlations.csv\n",
            "disp_st27ns1.txt.bz2\t    T1_TreeEvaluation.ipynb\n"
          ]
        }
      ],
      "source": [
        "# mount drive Gastón\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Abrir el path concreto\n",
        "#Insert here your own path. \n",
        "!ls\n",
        "%cd \"/content/drive/MyDrive/Aprendizaje\"\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ruta .pkl Gaston"
      ],
      "metadata": {
        "id": "P3DqPhfjDtw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/Aprendizaje/attrition_available_27.pkl', 'rb') as file:\n",
        "    datos = pickle.load(file)\n"
      ],
      "metadata": {
        "id": "Up19bfSnDTKr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examinar Datos\n",
        "\n",
        "Al tratarse de un **.pkl** no podemos saber de primeras que tipo de datos son, por tanto obtenemos mediante la siguiente función que su tipo corresponde a un Dataframe de dimensiones [4410 rows x 31 columns]"
      ],
      "metadata": {
        "id": "cyZN3SQ_E1A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tipo de objeto:\", type(datos))\n",
        "print(\"Contenido del objeto:\\n\", datos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KT-iyacEhtM",
        "outputId": "dafaebda-a7d1-45be-a898-3477de830471"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de objeto: <class 'pandas.core.frame.DataFrame'>\n",
            "Contenido del objeto:\n",
            "            hrs  absences  JobInvolvement  PerformanceRating  \\\n",
            "1     7.315971      13.0             2.0                4.0   \n",
            "6     6.450877      17.0             3.0                4.0   \n",
            "13    8.871421      14.0             2.0                3.0   \n",
            "28         NaN       6.0             2.0                3.0   \n",
            "30    9.662808      11.0             2.0                3.0   \n",
            "...        ...       ...             ...                ...   \n",
            "4405  8.316921       6.0             3.0                3.0   \n",
            "4406  5.897197       NaN             2.0                3.0   \n",
            "4407       NaN      18.0             3.0                4.0   \n",
            "4408  9.187612       NaN             2.0                3.0   \n",
            "4409  6.511790      17.0             4.0                3.0   \n",
            "\n",
            "      EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance   Age  \\\n",
            "1                         3.0              2.0              4.0  31.0   \n",
            "6                         1.0              3.0              1.0   NaN   \n",
            "13                        1.0              2.0              2.0   NaN   \n",
            "28                        4.0              3.0              1.0  44.0   \n",
            "30                        1.0              2.0              3.0  26.0   \n",
            "...                       ...              ...              ...   ...   \n",
            "4405                      4.0              1.0              3.0  42.0   \n",
            "4406                      4.0              4.0              3.0  29.0   \n",
            "4407                      1.0              3.0              3.0  25.0   \n",
            "4408                      4.0              1.0              NaN  42.0   \n",
            "4409                      NaN              3.0              NaN   NaN   \n",
            "\n",
            "     Attrition     BusinessTravel  ... NumCompaniesWorked  Over18  \\\n",
            "1          Yes  Travel_Frequently  ...                0.0       Y   \n",
            "6          Yes      Travel_Rarely  ...                2.0       Y   \n",
            "13         Yes         Non-Travel  ...                NaN       Y   \n",
            "28         Yes  Travel_Frequently  ...                NaN       Y   \n",
            "30         Yes                NaN  ...                2.0     NaN   \n",
            "...        ...                ...  ...                ...     ...   \n",
            "4405        No      Travel_Rarely  ...                NaN       Y   \n",
            "4406        No      Travel_Rarely  ...                2.0       Y   \n",
            "4407        No      Travel_Rarely  ...                0.0       Y   \n",
            "4408        No      Travel_Rarely  ...                0.0       Y   \n",
            "4409        No      Travel_Rarely  ...                NaN       Y   \n",
            "\n",
            "      PercentSalaryHike StandardHours  StockOptionLevel  TotalWorkingYears  \\\n",
            "1                  23.0             8               NaN                6.0   \n",
            "6                  20.0             8               1.0                5.0   \n",
            "13                 11.0             8               2.0               10.0   \n",
            "28                 14.0             8               1.0               19.0   \n",
            "30                 11.0             8               0.0                NaN   \n",
            "...                 ...           ...               ...                ...   \n",
            "4405               17.0             8               1.0               10.0   \n",
            "4406               15.0             8               0.0                NaN   \n",
            "4407                NaN             8               0.0                NaN   \n",
            "4408               14.0             8               NaN               10.0   \n",
            "4409               12.0             8               NaN                NaN   \n",
            "\n",
            "     TrainingTimesLastYear  YearsAtCompany YearsSinceLastPromotion  \\\n",
            "1                      NaN             NaN                       1   \n",
            "6                      2.0             0.0                       0   \n",
            "13                     4.0            10.0                       9   \n",
            "28                     2.0             1.0                       0   \n",
            "30                     5.0             3.0                       0   \n",
            "...                    ...             ...                     ...   \n",
            "4405                   5.0             NaN                       0   \n",
            "4406                   2.0             3.0                       0   \n",
            "4407                   4.0             NaN                       1   \n",
            "4408                   2.0             9.0                       7   \n",
            "4409                   6.0            21.0                       3   \n",
            "\n",
            "     YearsWithCurrManager  \n",
            "1                     4.0  \n",
            "6                     0.0  \n",
            "13                    9.0  \n",
            "28                    0.0  \n",
            "30                    2.0  \n",
            "...                   ...  \n",
            "4405                  2.0  \n",
            "4406                  NaN  \n",
            "4407                  NaN  \n",
            "4408                  8.0  \n",
            "4409                  9.0  \n",
            "\n",
            "[4410 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA del Dataframe"
      ],
      "metadata": {
        "id": "EAwjiUNUFYXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar y con el objetivo de seguir la estructura del enunciado realizaremos el análisis sobre el número de instancias y atributos"
      ],
      "metadata": {
        "id": "5O9D-qLtGAKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Número de instancias:\", datos.shape[0])\n",
        "print(\"Número de atributos:\", datos.shape[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU_NRB3-FX5x",
        "outputId": "170ce00a-e7a4-4873-8e84-eebecc31a909"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de instancias: 4410\n",
            "Número de atributos: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, el DataFrame tiene 4,410 instancias y 31 atributos:\n",
        "\n",
        "* 4,410 instancias (filas) representan 4,410 empleados individuales en el conjunto de datos.\n",
        "\n",
        "* 31 atributos (columnas) representan las características de cada empleado, como horas trabajadas, satisfacción laboral, edad, etc."
      ],
      "metadata": {
        "id": "w7qVJ79HGlHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tipos de atributos:\")\n",
        "print(datos.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LUQI5rvGtY3",
        "outputId": "cee95ae0-5fcb-4b0e-f975-9e01bd4b7760"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipos de atributos:\n",
            "hrs                        float64\n",
            "absences                   float64\n",
            "JobInvolvement             float64\n",
            "PerformanceRating          float64\n",
            "EnvironmentSatisfaction    float64\n",
            "JobSatisfaction            float64\n",
            "WorkLifeBalance            float64\n",
            "Age                        float64\n",
            "Attrition                   object\n",
            "BusinessTravel              object\n",
            "Department                  object\n",
            "DistanceFromHome           float64\n",
            "Education                  float64\n",
            "EducationField              object\n",
            "EmployeeCount              float64\n",
            "EmployeeID                 float64\n",
            "Gender                      object\n",
            "JobLevel                   float64\n",
            "JobRole                     object\n",
            "MaritalStatus               object\n",
            "MonthlyIncome              float64\n",
            "NumCompaniesWorked         float64\n",
            "Over18                      object\n",
            "PercentSalaryHike          float64\n",
            "StandardHours                int64\n",
            "StockOptionLevel           float64\n",
            "TotalWorkingYears          float64\n",
            "TrainingTimesLastYear      float64\n",
            "YearsAtCompany             float64\n",
            "YearsSinceLastPromotion      int64\n",
            "YearsWithCurrManager       float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **float64**: representa números de punto flotante (decimales), es decir, variables numéricas continuas. Por ejemplo, *hrs, absences, Age, MonthlyIncome, etc*.\n",
        "* **int64**: representa números enteros, es decir, variables numéricas discretas. En este caso, hay dos columnas con este tipo de datos: *StandardHours y YearsSinceLastPromotion.*\n",
        "* **object**: representa variables categóricas o de texto. Estas columnas contienen información en forma de texto o categorías, como *Attrition, BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus y Over18.*\n",
        "\n",
        "Conocer los tipos de atributos es útil para determinar qué técnicas de preprocesamiento aplicar a cada columna antes de entrenar un modelo de aprendizaje automático. Por ejemplo, las variables categóricas generalmente requieren ser transformadas en variables numéricas (a través de codificación one-hot, codificación ordinal, etc.) antes de utilizarlas en un modelo de aprendizaje automático. Además, las variables numéricas pueden requerir escalado o normalización dependiendo del algoritmo que se vaya a utilizar."
      ],
      "metadata": {
        "id": "s9y3zvWAG17p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_constantes = [col for col in datos.columns if datos[col].nunique() <= 1]\n",
        "print(\"Columnas constantes o innecesarias:\", columnas_constantes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK9UxnzrHhti",
        "outputId": "a8c43c40-b0fa-411d-ddf9-ff1ba7cbe8f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas constantes o innecesarias: ['EmployeeCount', 'Over18', 'StandardHours']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las columnas constantes o innecesarias son aquellas que tienen el mismo valor para todas las instancias o que no proporcionan información útil para el análisis o la construcción del modelo de aprendizaje automático.\n",
        "\n",
        "En este caso, se han identificado las siguientes columnas como constantes o innecesarias:\n",
        "\n",
        "* '**EmployeeCount**': Esta columna tiene el mismo valor para todos los empleados. No proporciona información útil para predecir la atrición de los empleados, ya que no hay variabilidad en sus datos.\n",
        "\n",
        "* '**Over18**': Esta columna indica si el empleado tiene más de 18 años de edad. Si todos los empleados tienen más de 18 años, entonces esta columna no aporta información útil para predecir la atrición de los empleados, ya que todos los empleados cumplen con este criterio.\n",
        "\n",
        "* '**StandardHours**': Si todas las instancias tienen el mismo valor para las horas estándar, entonces no hay variabilidad en esta columna, y no aporta información útil para predecir la atrición de los empleados."
      ],
      "metadata": {
        "id": "SOWFTHrRH1AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PROCEDEMOS A ELIMINAR LAS COLUMNAS\n",
        "datos = datos.drop(['EmployeeCount', 'Over18', 'StandardHours'], axis=1)\n"
      ],
      "metadata": {
        "id": "NZ5D1vSnH_T3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------\n",
        "#Miramos la proporcion de missing values por atributo\n",
        "\n",
        "print(\"Proporción de missing values por atributo:\")\n",
        "print(datos.isnull().sum() / datos.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5BUNThpIG0h",
        "outputId": "72f70773-95e7-4c86-afdf-c85641cb4cff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proporción de missing values por atributo:\n",
            "hrs                        0.205215\n",
            "absences                   0.202041\n",
            "JobInvolvement             0.162812\n",
            "PerformanceRating          0.208390\n",
            "EnvironmentSatisfaction    0.199320\n",
            "JobSatisfaction            0.214966\n",
            "WorkLifeBalance            0.174376\n",
            "Age                        0.166893\n",
            "Attrition                  0.000000\n",
            "BusinessTravel             0.192517\n",
            "Department                 0.177324\n",
            "DistanceFromHome           0.169388\n",
            "Education                  0.162132\n",
            "EducationField             0.160998\n",
            "EmployeeID                 0.180499\n",
            "Gender                     0.211338\n",
            "JobLevel                   0.177324\n",
            "JobRole                    0.177324\n",
            "MaritalStatus              0.000000\n",
            "MonthlyIncome              0.210658\n",
            "NumCompaniesWorked         0.212245\n",
            "PercentSalaryHike          0.178685\n",
            "StockOptionLevel           0.160544\n",
            "TotalWorkingYears          0.203628\n",
            "TrainingTimesLastYear      0.201134\n",
            "YearsAtCompany             0.216780\n",
            "YearsSinceLastPromotion    0.000000\n",
            "YearsWithCurrManager       0.202948\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Añadir texto sobre el tratamiento de los missing values"
      ],
      "metadata": {
        "id": "NczQhhfHKFQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tipo de problema (clasificación o regresión):\n",
        "\n",
        "Dado que el objetivo es predecir si los empleados abandonarán la empresa, es un problema de clasificación binaria."
      ],
      "metadata": {
        "id": "oLoWCw2pKd9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proporcion_clases = datos['Attrition'].value_counts(normalize=True)\n",
        "print(\"Proporción de clases:\\n\", proporcion_clases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMlcUUbWKL5D",
        "outputId": "af79432a-2259-4944-be6d-6a50fdbfbe94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proporción de clases:\n",
            " No     0.838776\n",
            "Yes    0.161224\n",
            "Name: Attrition, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, la proporción de clases para la columna 'Attrition' es la siguiente:\n",
        "\n",
        "* No (empleados que no abandonaron la empresa): 83.88%\n",
        "* Yes (empleados que abandonaron la empresa): 16.12%\n",
        "\n",
        "La diferencia en la proporción de clases indica que el conjunto de datos es desbalanceado. La clase \"Yes\" está subrepresentada en comparación con la clase \"No\"."
      ],
      "metadata": {
        "id": "Xs2bMfPsK0fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Añadir texto sobre tecnica de undersampling, oversampling etc"
      ],
      "metadata": {
        "id": "rEtzhsOjK-z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "aD56UXfSLhFZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Texto sobre las métricas\n",
        "\n",
        "\n",
        "\n",
        "* La métrica de **balanced_accuracy** (precisión equilibrada) es una medida que tiene en cuenta el desbalanceo de clases, calculando la precisión por cada clase y luego promediándolas. Es útil cuando las proporciones de las clases son desiguales, ya que proporciona una visión más justa del rendimiento del modelo en comparación con la precisión estándar.\n",
        "\n",
        "* El **F1 score** es otra métrica que combina la precisión y la exhaustividad (recall) en un solo valor. Es especialmente útil cuando las clases están desbalanceadas, ya que da igual importancia a la precisión y a la exhaustividad, lo que significa que penaliza más los falsos positivos y falsos negativos que la precisión estándar.\n",
        "\n",
        "* La **matriz de confusión** es una tabla que muestra la cantidad de verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos que se produjeron en la clasificación. Es útil para visualizar el rendimiento del modelo y obtener información sobre las clases que se clasificaron incorrectamente."
      ],
      "metadata": {
        "id": "-zO-8FLSMb2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realizamos la partición"
      ],
      "metadata": {
        "id": "OSr2UKjLLlvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Falta limpiar el dataframe y cambiar por version descomentada\n",
        "\n",
        "#X = datos_limpios.drop('Attrition', axis=1)\n",
        "#y = datos_limpios['Attrition']\n",
        "\n",
        "\n",
        "X = datos.drop('Attrition', axis=1)\n",
        "y = datos['Attrition']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
      ],
      "metadata": {
        "id": "ZwAjPwUhLocA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preporcesamiento de los datos"
      ],
      "metadata": {
        "id": "kwj6Pdl6OHqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())])\n",
        "\n",
        "# Separar las variables predictoras y la variable objetivo\n",
        "X = datos.drop('Attrition', axis=1)\n",
        "y = datos['Attrition']\n",
        "\n",
        "# Codificar las etiquetas 'No' y 'Yes' en 0 y 1\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Separar los datos en conjuntos de entrenamiento y prueba (estratificado)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Preprocesamiento\n",
        "numeric_features = [\n",
        "    'hrs', 'absences', 'JobInvolvement', 'PerformanceRating',\n",
        "    'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age',\n",
        "    'DistanceFromHome', 'Education', 'EmployeeID', 'JobLevel',\n",
        "    'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike',\n",
        "    'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
        "    'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager'\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    'BusinessTravel', 'Department', 'EducationField', 'Gender',\n",
        "    'JobRole', 'MaritalStatus'\n",
        "]\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Aplicar preprocesamiento\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "\n",
        "X = pd.get_dummies(X, columns=categorical_features)\n",
        "\n",
        "\n",
        "# Verificar si el one-hot encoding se aplicó correctamente\n",
        "print(\"X_train después del preprocesamiento:\")\n",
        "print(X_train_processed)\n",
        "X_train.select_dtypes('object').columns\n",
        "\n",
        "#--------------------------------Revisar si hace falta un segundo barrido de valores negativos ----------------------------------------------\n",
        "\n",
        "# Crear un objeto MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Aplicar la transformación MinMaxScaler solo a las características con valores negativos\n",
        "X_train_processed[:, :len(numeric_features)] = scaler.fit_transform(X_train_processed[:, :len(numeric_features)])\n",
        "X_test_processed[:, :len(numeric_features)] = scaler.transform(X_test_processed[:, :len(numeric_features)])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ5cNUN3L9Ai",
        "outputId": "5ac7c10d-1485-425a-cbd7-d652b78e8995"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train después del preprocesamiento:\n",
            "[[-0.19718329 -0.96930027  1.87537061 ...  0.          1.\n",
            "   0.        ]\n",
            " [-0.19718329 -0.76533442  0.34417239 ...  0.          1.\n",
            "   0.        ]\n",
            " [-0.19718329 -1.37723195  0.34417239 ...  0.          0.\n",
            "   1.        ]\n",
            " ...\n",
            " [-0.19718329 -1.5811978   0.34417239 ...  0.          1.\n",
            "   0.        ]\n",
            " [-0.60781977  0.05052895  0.34417239 ...  0.          0.\n",
            "   1.        ]\n",
            " [-0.300564   -1.17326611 -2.71822406 ...  0.          1.\n",
            "   0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Buscamos variables negativas que entorpecen el chi2"
      ],
      "metadata": {
        "id": "vKfi4J-L2SiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame de características procesadas para facilitar la inspección\n",
        "feature_names = numeric_features + preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features).tolist()\n",
        "X_train_df = pd.DataFrame(X_train_processed, columns=feature_names)\n",
        "\n",
        "# Identificar características con valores negativos\n",
        "negative_value_features = []\n",
        "for column in X_train_df.columns:\n",
        "    if X_train_df[column].min() < 0:\n",
        "        negative_value_features.append(column)\n",
        "        print(f\"Característica '{column}' tiene un valor mínimo de {X_train_df[column].min()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QZFCfuGv2BtY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento de un modelo de Regresión logística y evaluación"
      ],
      "metadata": {
        "id": "MwKNvocKON8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "logreg = LogisticRegression(class_weight='balanced', random_state=42)\n",
        "logreg.fit(X_train_processed, y_train)\n",
        "\n",
        "y_pred_logreg = logreg.predict(X_test_processed)\n",
        "\n",
        "balanced_acc_logreg = balanced_accuracy_score(y_test, y_pred_logreg)\n",
        "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
        "conf_matrix_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
        "\n",
        "print(\"Balanced Accuracy (Logistic Regression):\", balanced_acc_logreg)\n",
        "print(\"F1 Score (Logistic Regression):\", f1_logreg)\n",
        "print(\"Confusion Matrix (Logistic Regression):\\n\", conf_matrix_logreg)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMd9UjS3OXuK",
        "outputId": "28eb0c0a-3f38-4b83-d385-524aca12ed26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Accuracy (Logistic Regression): 0.7188618195660449\n",
            "F1 Score (Logistic Regression): 0.4572748267898384\n",
            "Confusion Matrix (Logistic Regression):\n",
            " [[548 192]\n",
            " [ 43  99]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La matriz de confusión muestra que de los casos negativos (No), 548 fueron clasificados correctamente y 192 incorrectamente. De los casos positivos (Yes), 99 fueron clasificados correctamente y 43 incorrectamente.\n",
        "\n",
        "La precisión equilibrada es una medida útil en problemas de clasificación desequilibrados, ya que tiene en cuenta tanto la tasa de verdaderos positivos como la tasa de verdaderos negativos. Un valor más alto indica un mejor rendimiento del modelo. En este caso, el modelo de regresión logística tiene una precisión equilibrada de aproximadamente el 71.89%.\n",
        "\n",
        "El F1 Score es una métrica que combina la precisión y el recall en un solo valor, siendo útil cuando se tiene un conjunto de datos desequilibrados y se quiere medir el rendimiento del modelo en la clasificación de la clase minoritaria. Un valor más alto indica un mejor rendimiento del modelo. En este caso, el modelo de regresión logística tiene un F1 Score de aproximadamente el 45.73%."
      ],
      "metadata": {
        "id": "v-Yc052SOn7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementación de la Parte Adicional"
      ],
      "metadata": {
        "id": "MOFiBugGO1Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xgboost\") #nos permite filtrar que \"el parámetro use_label_encoder se ha marcado como obsoleto a partir de la versión 1.7.0 de XGBoost y ya no se recomienda su uso.\"\"\n",
        "\n",
        "# El resto del código de la celda 3\n",
        "\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, objective=\"binary:logistic\", eval_metric=\"logloss\", random_state=42)\n",
        "\n",
        "# Ajustar hiperparámetros\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(xgb_clf, param_grid, scoring='balanced_accuracy', cv=5)\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "best_xgb = grid_search.best_estimator_\n",
        "\n",
        "y_pred_xgb = best_xgb.predict(X_test_processed)\n",
        "\n",
        "balanced_acc_xgb = balanced_accuracy_score(y_test, y_pred_xgb)\n",
        "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
        "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "\n",
        "print(\"Balanced Accuracy (XGBoost):\", balanced_acc_xgb)\n",
        "print(\"F1 Score (XGBoost):\", f1_xgb)\n",
        "print(\"Confusion Matrix (XGBoost):\\n\", conf_matrix_xgb)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Td6GqU4BOpg3",
        "outputId": "05fa6321-fa40-4c42-a1f4-c9d38f56ac5b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-79b17f792906>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mbest_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                                                     dtrain.handle))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Balanced Accuracy:** Se trata de una media de la recuperación (sensibilidad) obtenida en cada clase, y resulta útil cuando se trabaja con conjuntos de datos desequilibrados. Su modelo tiene una precisión equilibrada del 81,35%, lo que significa que clasifica correctamente el 81,35% de las instancias de media en ambas clases.\n",
        "\n",
        "* **Puntuación F1:** Es la media armónica de la precisión y la recuperación, y da más peso al valor más bajo. Es una buena métrica cuando los falsos positivos y los falsos negativos tienen la misma importancia. Una puntuación F1 del 75,95% indica que el modelo tiene un rendimiento razonablemente bueno en términos de precisión y recuperación.\n",
        "\n",
        "* **Matriz de confusión:** La matriz de confusión es una tabla que muestra el número de predicciones positivas verdaderas (TP), negativas verdaderas (TN), positivas falsas (FP) y negativas falsas (FN) para un problema de clasificación binaria. \n",
        "\n",
        "A partir de la **matriz de confusión**, podemos ver que el modelo tiene un número relativamente bajo de falsos positivos (5) y un número más alto de falsos negativos (52). Esto podría indicar que el modelo es más conservador a la hora de predecir la clase positiva, lo que podría dar lugar a una menor recuperación de la clase positiva.\n",
        "\n",
        "En general, su modelo muestra un rendimiento razonablemente bueno, pero puede que desee considerar métodos para mejorar la recuperación de la clase positiva, como utilizar técnicas para manejar datos desequilibrados o ajustar el umbral de decisión."
      ],
      "metadata": {
        "id": "JK8TcxJOpvcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método de Selección de Atributos"
      ],
      "metadata": {
        "id": "apvtayZmvO4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, chi2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
      ],
      "metadata": {
        "id": "nsPOIah3vKNc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importante\n",
        "* Necesitamos one hot encoding para eliminar las categoricas (tocará analizar el impacto ya que se agranda el espacio\n",
        "* chi2 test solo acepta positivos usar MinMaxScaler en lugar de StandardScaler"
      ],
      "metadata": {
        "id": "MSVsLHda1WpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un objeto SelectKBest para cada método de selección\n",
        "kbest_f_classif = SelectKBest(score_func=f_classif, k='all')\n",
        "kbest_mutual_info = SelectKBest(score_func=mutual_info_classif, k='all')\n",
        "kbest_chi2 = SelectKBest(score_func=chi2, k='all')\n",
        "\n",
        "\n",
        "# Ajustar y transformar los datos de entrenamiento y prueba\n",
        "X_train_f_classif = kbest_f_classif.fit_transform(X_train_processed, y_train)\n",
        "X_test_f_classif = kbest_f_classif.transform(X_test_processed)\n",
        "\n",
        "X_train_mutual_info = kbest_mutual_info.fit_transform(X_train_processed, y_train)\n",
        "X_test_mutual_info = kbest_mutual_info.transform(X_test_processed)\n",
        "\n",
        "X_train_chi2 = kbest_chi2.fit_transform(X_train_processed, y_train)\n",
        "X_test_chi2 = kbest_chi2.transform(X_test_processed)\n",
        "\n"
      ],
      "metadata": {
        "id": "a1XuWVFhvV0a"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y ajustar el modelo de clasificación\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Para f_classif\n",
        "classifier.fit(X_train_f_classif, y_train)\n",
        "y_pred_f_classif = classifier.predict(X_test_f_classif)\n",
        "print(\"Resultados con f_classif:\")\n",
        "print(classification_report(y_test, y_pred_f_classif))\n",
        "\n",
        "# Para mutual_info_classif\n",
        "classifier.fit(X_train_mutual_info, y_train)\n",
        "y_pred_mutual_info = classifier.predict(X_test_mutual_info)\n",
        "print(\"Resultados con mutual_info_classif:\")\n",
        "print(classification_report(y_test, y_pred_mutual_info))\n",
        "\n",
        "# Para chi2\n",
        "classifier.fit(X_train_chi2, y_train)\n",
        "y_pred_chi2 = classifier.predict(X_test_chi2)\n",
        "print(\"Resultados con chi2:\")\n",
        "print(classification_report(y_test, y_pred_chi2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KakOYN33bWe",
        "outputId": "ad1e89ae-aa75-49be-9c5e-54aa901ace9b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados con f_classif:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92       740\n",
            "           1       0.63      0.17      0.27       142\n",
            "\n",
            "    accuracy                           0.85       882\n",
            "   macro avg       0.75      0.58      0.59       882\n",
            "weighted avg       0.82      0.85      0.81       882\n",
            "\n",
            "Resultados con mutual_info_classif:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92       740\n",
            "           1       0.63      0.17      0.27       142\n",
            "\n",
            "    accuracy                           0.85       882\n",
            "   macro avg       0.75      0.58      0.59       882\n",
            "weighted avg       0.82      0.85      0.81       882\n",
            "\n",
            "Resultados con chi2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92       740\n",
            "           1       0.63      0.17      0.27       142\n",
            "\n",
            "    accuracy                           0.85       882\n",
            "   macro avg       0.75      0.58      0.59       882\n",
            "weighted avg       0.82      0.85      0.81       882\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir los resultados de cada método de selección\n",
        "print(\"Importancia de los atributos según f_classif:\")\n",
        "for i, score in enumerate(kbest_f_classif.scores_):\n",
        "    print(f\"Atributo {i}: {score}\")\n",
        "\n",
        "print(\"Importancia de los atributos según mutual_info_classif:\")\n",
        "for i, score in enumerate(kbest_mutual_info.scores_):\n",
        "    print(f\"Atributo {i}: {score}\")\n",
        "\n",
        "print(\"Importancia de los atributos según chi2:\")\n",
        "for i, score in enumerate(kbest_chi2.scores_):\n",
        "    print(f\"Atributo {i}: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxVq2W9f3dOw",
        "outputId": "af53ae60-4e7a-4b3b-f4c0-d7bce7b18556"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importancia de los atributos según f_classif:\n",
            "Atributo 0: 113.0737368969395\n",
            "Atributo 1: 2.3174745782517574\n",
            "Atributo 2: 0.32249959120758465\n",
            "Atributo 3: 2.3976941378156638\n",
            "Atributo 4: 36.706412668522944\n",
            "Atributo 5: 28.1627799032299\n",
            "Atributo 6: 13.203854530035821\n",
            "Atributo 7: 78.36247954309822\n",
            "Atributo 8: 0.23274098855794836\n",
            "Atributo 9: 0.08296141215829432\n",
            "Atributo 10: 0.04386979950975095\n",
            "Atributo 11: 0.7514586086810724\n",
            "Atributo 12: 4.278485000699727\n",
            "Atributo 13: 3.9467056684591846\n",
            "Atributo 14: 3.0596455214161655\n",
            "Atributo 15: 0.5194550476964118\n",
            "Atributo 16: 99.17510586391975\n",
            "Atributo 17: 4.238218974750357\n",
            "Atributo 18: 65.15578780804957\n",
            "Atributo 19: 6.379768495252653\n",
            "Atributo 20: 82.46235154445615\n",
            "Atributo 21: 11.611449990037835\n",
            "Atributo 22: 44.41915917837392\n",
            "Atributo 23: 6.542138868411917\n",
            "Atributo 24: 0.202187693997351\n",
            "Atributo 25: 8.528182115986413\n",
            "Atributo 26: 0.13147966186272092\n",
            "Atributo 27: 1.667020813015562\n",
            "Atributo 28: 0.21538627665592472\n",
            "Atributo 29: 28.103745801175243\n",
            "Atributo 30: 0.00018279521315450655\n",
            "Atributo 31: 0.040388006519970016\n",
            "Atributo 32: 0.004109679087482352\n",
            "Atributo 33: 0.05539334297137575\n",
            "Atributo 34: 2.953339979589828\n",
            "Atributo 35: 0.2388272390097854\n",
            "Atributo 36: 2.9744565027192493\n",
            "Atributo 37: 1.7204769960955795\n",
            "Atributo 38: 0.12827302178573902\n",
            "Atributo 39: 0.0012068394390457827\n",
            "Atributo 40: 0.7442165121752405\n",
            "Atributo 41: 0.6896967558270691\n",
            "Atributo 42: 0.6599253710343318\n",
            "Atributo 43: 5.362962916175088\n",
            "Atributo 44: 2.0807665294505497\n",
            "Atributo 45: 2.4323328450682777\n",
            "Atributo 46: 2.3049083290012513\n",
            "Atributo 47: 0.19889524102680606\n",
            "Atributo 48: 0.6023026496764813\n",
            "Atributo 49: 26.676196270533495\n",
            "Atributo 50: 36.35989887411164\n",
            "Atributo 51: 124.5179424472822\n",
            "Importancia de los atributos según mutual_info_classif:\n",
            "Atributo 0: 0.017066856062453395\n",
            "Atributo 1: 0.0\n",
            "Atributo 2: 0.0\n",
            "Atributo 3: 0.0039502174379442145\n",
            "Atributo 4: 0.0\n",
            "Atributo 5: 0.0014533158411609293\n",
            "Atributo 6: 0.0\n",
            "Atributo 7: 0.026805376249506185\n",
            "Atributo 8: 0.0\n",
            "Atributo 9: 0.004123428867652823\n",
            "Atributo 10: 0.0\n",
            "Atributo 11: 0.0\n",
            "Atributo 12: 0.07913869463486889\n",
            "Atributo 13: 0.01821192025307483\n",
            "Atributo 14: 0.0\n",
            "Atributo 15: 0.0\n",
            "Atributo 16: 0.03768965341099095\n",
            "Atributo 17: 0.0016868101992366658\n",
            "Atributo 18: 0.023535001909423814\n",
            "Atributo 19: 0.011090794224727363\n",
            "Atributo 20: 0.011498994461566436\n",
            "Atributo 21: 0.005595998498802768\n",
            "Atributo 22: 0.0\n",
            "Atributo 23: 0.0017504750876666808\n",
            "Atributo 24: 0.004130767868267382\n",
            "Atributo 25: 0.011699319301949673\n",
            "Atributo 26: 0.0\n",
            "Atributo 27: 0.0\n",
            "Atributo 28: 0.0051472752772554475\n",
            "Atributo 29: 0.010796956785910972\n",
            "Atributo 30: 0.005452698963162916\n",
            "Atributo 31: 0.0\n",
            "Atributo 32: 0.006318809823955052\n",
            "Atributo 33: 0.0\n",
            "Atributo 34: 0.0\n",
            "Atributo 35: 0.0\n",
            "Atributo 36: 0.0\n",
            "Atributo 37: 0.011530763723618609\n",
            "Atributo 38: 0.0\n",
            "Atributo 39: 0.007731080101701648\n",
            "Atributo 40: 0.0\n",
            "Atributo 41: 0.0007200732072525362\n",
            "Atributo 42: 0.0\n",
            "Atributo 43: 0.0\n",
            "Atributo 44: 0.002443192735219535\n",
            "Atributo 45: 0.0\n",
            "Atributo 46: 0.0\n",
            "Atributo 47: 0.0\n",
            "Atributo 48: 0.0061829302771798655\n",
            "Atributo 49: 0.0\n",
            "Atributo 50: 0.0\n",
            "Atributo 51: 0.015241327897500767\n",
            "Importancia de los atributos según chi2:\n",
            "Atributo 0: 15.340989354524552\n",
            "Atributo 1: 0.20606844799322835\n",
            "Atributo 2: 0.02584031437875589\n",
            "Atributo 3: 2.0950277343076196\n",
            "Atributo 4: 6.642774337116502\n",
            "Atributo 5: 5.345219569431472\n",
            "Atributo 6: 1.0295098420783881\n",
            "Atributo 7: 6.893671050800048\n",
            "Atributo 8: 0.059499911455679184\n",
            "Atributo 9: 0.009435272726504254\n",
            "Atributo 10: 0.005889376351146948\n",
            "Atributo 11: 0.17753264616692144\n",
            "Atributo 12: 0.8021942548462342\n",
            "Atributo 13: 0.8611406706722847\n",
            "Atributo 14: 0.6204419315270373\n",
            "Atributo 15: 0.12827021652398365\n",
            "Atributo 16: 10.64342623485779\n",
            "Atributo 17: 0.32914688012941995\n",
            "Atributo 18: 7.829706645116721\n",
            "Atributo 19: 1.9814177909588961\n",
            "Atributo 20: 12.50651978310738\n",
            "Atributo 21: 10.611628311497583\n",
            "Atributo 22: 37.18579272208277\n",
            "Atributo 23: 2.794612821121271\n",
            "Atributo 24: 0.16358718538241754\n",
            "Atributo 25: 8.186700014432752\n",
            "Atributo 26: 0.0608154658257826\n",
            "Atributo 27: 1.256526853485958\n",
            "Atributo 28: 0.177197227092399\n",
            "Atributo 29: 27.383351379218386\n",
            "Atributo 30: 0.00012058469760580636\n",
            "Atributo 31: 0.036985643583808354\n",
            "Atributo 32: 0.0030035821511672223\n",
            "Atributo 33: 0.05278465923568211\n",
            "Atributo 34: 2.7240716176826614\n",
            "Atributo 35: 0.2003412155562703\n",
            "Atributo 36: 2.035524071541648\n",
            "Atributo 37: 0.9081014744846588\n",
            "Atributo 38: 0.10109408959107186\n",
            "Atributo 39: 0.0011209296114513493\n",
            "Atributo 40: 0.7233794250777019\n",
            "Atributo 41: 0.5925616796052492\n",
            "Atributo 42: 0.6229383061203884\n",
            "Atributo 43: 4.905293055727353\n",
            "Atributo 44: 1.9875347726651151\n",
            "Atributo 45: 2.0328998499802293\n",
            "Atributo 46: 1.8866213173476334\n",
            "Atributo 47: 0.1899156276865303\n",
            "Atributo 48: 0.49289522826558996\n",
            "Atributo 49: 20.641583836061\n",
            "Atributo 50: 19.535602359279974\n",
            "Atributo 51: 81.62442726595351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importancia de los atributos\n",
        "\n",
        "**f_classif:** Este método evalúa la importancia de las características basándose en la relación entre la variación de cada característica y la variación de la variable objetivo (en este caso, la clase). Los valores más altos indican una mayor importancia. Algunas de las características con valores más altos en tus resultados son:\n",
        "\n",
        "* Atributo 0\n",
        "* Atributo 7\n",
        "* Atributo 16\n",
        "* Atributo 18\n",
        "* Atributo 20\n",
        "* Atributo 22\n",
        "* Atributo 29\n",
        "* Atributo 51\n",
        "\n",
        "**mutual_info_classif:** Este método mide la dependencia mutua entre cada característica y la variable objetivo. Los valores más altos indican una mayor dependencia, y por lo tanto, una mayor importancia. Algunas de las características con valores más altos en tus resultados son:\n",
        "\n",
        "* Atributo 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Atributo 7\n",
        "* Atributo 12\n",
        "* Atributo 13\n",
        "* Atributo 16\n",
        "* Atributo 18\n",
        "* Atributo 20\n",
        "* Atributo 25\n",
        "* Atributo 29\n",
        "* Atributo 37\n",
        "* Atributo 51\n",
        "\n",
        "**chi2:** Este método evalúa la importancia de las características basándose en la prueba estadística chi-cuadrado. Los valores más altos indican una mayor dependencia entre la característica y la variable objetivo. Algunas de las características con valores más altos en tus resultados son:\n",
        "\n",
        "* Atributo 0\n",
        "* Atributo 7\n",
        "* Atributo 16\n",
        "* Atributo 18\n",
        "* Atributo 20\n",
        "* Atributo 21\n",
        "* Atributo 22\n",
        "* Atributo 29\n",
        "* Atributo 43\n",
        "* Atributo 49\n",
        "* Atributo 50\n",
        "* Atributo 51\n",
        "\n",
        "A partir de estos resultados, puedes ver que algunos atributos parecen ser más importantes en los tres métodos, como los atributos 0, 7, 16, 18, 20, 29 y 51. Estos podrían ser buenos candidatos para probar en tu modelo."
      ],
      "metadata": {
        "id": "oHl3Npzl4OeH"
      }
    }
  ]
}